{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac7de26",
   "metadata": {},
   "source": [
    "# Import The necessary libraries(though I havent used all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94872eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import glob\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0b495",
   "metadata": {},
   "source": [
    "# Shown an example ofhow loading a sample image works..All the photos are taken on laptop camera...one thing to keep in mind..you cant keep a folder named 'angry\"...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b896aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"D:\\Study Materials\\PROJECT\\Dataset\\mad\\WIN_20240209_20_34_03_Pro.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45581e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "arr = np.asarray(img)\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a46ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424073f",
   "metadata": {},
   "source": [
    "# Next I will be creating a list in a loop and resizing it cz I am running the code on a toaster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bc01f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_happy = [resize(cv2.imread(file),(288,512,3)) for file in glob.glob(\"D:\\Study Materials\\PROJECT\\Dataset\\happy\\*.jpg\")]\n",
    "images_sad = [resize(cv2.imread(file),(288,512,3)) for file in glob.glob(\"D:\\Study Materials\\PROJECT\\Dataset\\sad\\*.jpg\")]\n",
    "images_angry = [resize(cv2.imread(file),(288,512,3)) for file in glob.glob(\"D:\\Study Materials\\PROJECT\\Dataset\\mad\\*.jpg\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36973d05",
   "metadata": {},
   "source": [
    "# Convert the list to an array for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "559d3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_happy_array=np.array(images_happy)\n",
    "images_sad_array=np.array(images_sad)\n",
    "images_angry_array=np.array(images_angry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6c003f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(images_angry_array[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc8cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "957ebb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 288, 512, 3)\n",
      "(24, 288, 512, 3)\n",
      "(34, 288, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_happy_array.shape)\n",
    "print(images_sad_array.shape)\n",
    "print(images_angry_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc93c7",
   "metadata": {},
   "source": [
    "# Next we are concatenating the features based on their number that is the 0th axis..see the first dimension is increasing.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33b68ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((images_happy_array,images_sad_array,images_angry_array),axis = 0)\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77e690d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 288, 512, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a42d49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_happy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe40690",
   "metadata": {},
   "source": [
    "# There are 3 labels...happy sad angry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bcbfd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c001d",
   "metadata": {},
   "source": [
    "# Assigning the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5586c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.repeat(labels,np.array([len(images_happy_array),len(images_sad_array),len(images_angry_array)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf73e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba4255c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d28ff367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "y_categorical = keras.utils.to_categorical(\n",
    "    y, num_classes=3, dtype='float32'\n",
    ")\n",
    "#y_categorical[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a3fb8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y_categorical,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19352fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 288, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea26e7",
   "metadata": {},
   "source": [
    "# Provided a sample model...keep an eye on the input shape...Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4ec5e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 6s 1s/step - loss: 1.1111 - accuracy: 0.4051\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0891 - accuracy: 0.4051\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0678 - accuracy: 0.4051\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0811 - accuracy: 0.4051\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0781 - accuracy: 0.4051\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0778 - accuracy: 0.4051\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0757 - accuracy: 0.4051\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0719 - accuracy: 0.4051\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0708 - accuracy: 0.4051\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0776 - accuracy: 0.4051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cb9e080790>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(filters=32,padding='same', kernel_size=(3,3),  activation='relu', input_shape=(288,512,3)),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=32,padding='same', kernel_size=(3,3),  activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    #keras.layers.Dropout(0.2),\n",
    "    #keras.layers.Conv2D(filters=32,padding='same', kernel_size=(3,3),  activation='relu'),\n",
    "    #keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10,activation='relu'),\n",
    "    #keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "model_cnn.compile( \n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_cnn.fit(X_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e405028",
   "metadata": {},
   "source": [
    "# Your Test Results...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bfcfcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 282ms/step - loss: 1.1038 - accuracy: 0.4500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1038119792938232, 0.44999998807907104]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b43020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
